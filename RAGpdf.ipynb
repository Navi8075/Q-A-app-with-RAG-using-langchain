{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5a0f3f6",
   "metadata": {},
   "source": [
    "# RAG application built on gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9e35f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"yolov9_paper.pdf\")\n",
    "data = loader.load()  # entire PDF is loaded as a single Document\n",
    "#data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "056a151a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'yolov9_paper.pdf', 'page': 0}, page_content='YOLOv9: Learning What You Want to Learn\\nUsing Programmable Gradient Information\\nChien-Yao Wang1,2, I-Hau Yeh2, and Hong-Yuan Mark Liao1,2,3\\n1Institute of Information Science, Academia Sinica, Taiwan\\n2National Taipei University of Technology, Taiwan\\n3Department of Information and Computer Engineering, Chung Yuan Christian University, Taiwan\\nkinyiu@iis.sinica.edu.tw, ihyeh@emc.com.tw, and liao@iis.sinica.edu.tw\\nAbstract\\nToday’s deep learning methods focus on how to design\\nthe most appropriate objective functions so that the pre-\\ndiction results of the model can be closest to the ground\\ntruth. Meanwhile, an appropriate architecture that can\\nfacilitate acquisition of enough information for prediction\\nhas to be designed. Existing methods ignore a fact that\\nwhen input data undergoes layer-by-layer feature extrac-\\ntion and spatial transformation, large amount of informa-\\ntion will be lost. This paper will delve into the important is-\\nsues of data loss when data is transmitted through deep net-\\nworks, namely information bottleneck and reversible func-\\ntions. We proposed the concept of programmable gradi-\\nent information (PGI) to cope with the various changes\\nrequired by deep networks to achieve multiple objectives.\\nPGI can provide complete input information for the tar-\\nget task to calculate objective function, so that reliable\\ngradient information can be obtained to update network\\nweights. In addition, a new lightweight network architec-\\nture – Generalized Efficient Layer Aggregation Network\\n(GELAN), based on gradient path planning is designed.\\nGELAN’s architecture confirms that PGI has gained su-\\nperior results on lightweight models. We verified the pro-\\nposed GELAN and PGI on MS COCO dataset based ob-\\nject detection. The results show that GELAN only uses\\nconventional convolution operators to achieve better pa-\\nrameter utilization than the state-of-the-art methods devel-\\noped based on depth-wise convolution. PGI can be used\\nfor variety of models from lightweight to large. It can be\\nused to obtain complete information, so that train-from-\\nscratch models can achieve better results than state-of-the-\\nart models pre-trained using large datasets, the compari-\\nson results are shown in Figure 1. The source codes are at:\\nhttps://github.com/WongKinYiu/yolov9 .\\n1. Introduction\\nDeep learning-based models have demonstrated far bet-\\nter performance than past artificial intelligence systems in\\nvarious fields, such as computer vision, language process-\\ning, and speech recognition. In recent years, researchers\\nFigure 1. Comparisons of the real-time object detecors on MS\\nCOCO dataset. The GELAN and PGI-based object detection\\nmethod surpassed all previous train-from-scratch methods in terms\\nof object detection performance. In terms of accuracy, the new\\nmethod outperforms RT DETR [43] pre-trained with a large\\ndataset, and it also outperforms depth-wise convolution-based de-\\nsign YOLO MS [7] in terms of parameters utilization.\\nin the field of deep learning have mainly focused on how\\nto develop more powerful system architectures and learn-\\ning methods, such as CNNs [21–23, 42, 55, 71, 72], Trans-\\nformers [8, 9, 40, 41, 60, 69, 70], Perceivers [26, 26, 32, 52,\\n56, 81, 81], and Mambas [17, 38, 80]. In addition, some\\nresearchers have tried to develop more general objective\\nfunctions, such as loss function [5, 45, 46, 50, 77, 78], la-\\nbel assignment [10, 12, 33, 67, 79] and auxiliary supervi-\\nsion [18, 20, 24, 28, 29, 51, 54, 68, 76]. The above studies\\nall try to precisely find the mapping between input and tar-\\nget tasks. However, most past approaches have ignored that\\ninput data may have a non-negligible amount of informa-\\ntion loss during the feedforward process. This loss of in-\\nformation can lead to biased gradient flows, which are sub-\\nsequently used to update the model. The above problems\\ncan result in deep networks to establish incorrect associa-\\ntions between targets and inputs, causing the trained model\\nto produce incorrect predictions.\\n1arXiv:2402.13616v2  [cs.CV]  29 Feb 2024')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bdd2670c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of documents:  96\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# split data\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000)\n",
    "docs = text_splitter.split_documents(data)\n",
    "\n",
    "\n",
    "print(\"Total number of documents: \",len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95c597c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'yolov9_paper.pdf', 'page': 0}, page_content='when input data undergoes layer-by-layer feature extrac-\\ntion and spatial transformation, large amount of informa-\\ntion will be lost. This paper will delve into the important is-\\nsues of data loss when data is transmitted through deep net-\\nworks, namely information bottleneck and reversible func-\\ntions. We proposed the concept of programmable gradi-\\nent information (PGI) to cope with the various changes\\nrequired by deep networks to achieve multiple objectives.\\nPGI can provide complete input information for the tar-\\nget task to calculate objective function, so that reliable\\ngradient information can be obtained to update network\\nweights. In addition, a new lightweight network architec-\\nture – Generalized Efficient Layer Aggregation Network\\n(GELAN), based on gradient path planning is designed.\\nGELAN’s architecture confirms that PGI has gained su-\\nperior results on lightweight models. We verified the pro-\\nposed GELAN and PGI on MS COCO dataset based ob-')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62ad19fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.05168594419956207,\n",
       " -0.030764883384108543,\n",
       " -0.03062233328819275,\n",
       " -0.02802734449505806,\n",
       " 0.01813092641532421]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "#Get an API key: \n",
    "# Head to https://ai.google.dev/gemini-api/docs/api-key to generate a Google AI API key. Paste in .env file\n",
    "\n",
    "# Embedding models: https://python.langchain.com/v0.1/docs/integrations/text_embedding/\n",
    "\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "vector = embeddings.embed_query(\"hello, world!\")\n",
    "vector[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8941ee7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = Chroma.from_documents(documents=docs, embedding=GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3aceea86",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 10})\n",
    "\n",
    "retrieved_docs = retriever.invoke(\"What is new in yolov9?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ce94eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLOv9: Learning What You Want to Learn\n",
      "Using Programmable Gradient Information\n",
      "Chien-Yao Wang1,2, I-Hau Yeh2, and Hong-Yuan Mark Liao1,2,3\n",
      "1Institute of Information Science, Academia Sinica, Taiwan\n",
      "2National Taipei University of Technology, Taiwan\n",
      "3Department of Information and Computer Engineering, Chung Yuan Christian University, Taiwan\n",
      "kinyiu@iis.sinica.edu.tw, ihyeh@emc.com.tw, and liao@iis.sinica.edu.tw\n",
      "Abstract\n",
      "Today’s deep learning methods focus on how to design\n",
      "the most appropriate objective functions so that the pre-\n",
      "diction results of the model can be closest to the ground\n",
      "truth. Meanwhile, an appropriate architecture that can\n",
      "facilitate acquisition of enough information for prediction\n",
      "has to be designed. Existing methods ignore a fact that\n",
      "when input data undergoes layer-by-layer feature extrac-\n",
      "tion and spatial transformation, large amount of informa-\n",
      "tion will be lost. This paper will delve into the important is-\n"
     ]
    }
   ],
   "source": [
    "print(retrieved_docs[5].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "67411e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\",temperature=0.3, max_tokens=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6c9fdab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you don't know the answer, say that you \"\n",
    "    \"don't know. Use three sentences maximum and keep the \"\n",
    "    \"answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f1af2040",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8f15d186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLOv9 introduces two new components: **Programmable Gradient Information (PGI)** and **Generalized ELAN (GELAN)**. PGI helps the model learn more effectively by manipulating gradient flow, while GELAN improves architecture flexibility for better accuracy and speed trade-offs. Together, these enhancements allow YOLOv9 to achieve state-of-the-art performance in object detection. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"input\": \"what is new in YOLOv9?\"})\n",
    "print(response[\"answer\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
